{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b2d6291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sandu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.wsd import lesk\n",
    "import difflib\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "76372ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('school.n.06')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b5794300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the school was founded in 1900'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synset('school.n.01').examples()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4b8d14f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('school.n.03')\n",
      "the process of being formally educated at a school\n",
      "Synset('school.n.05')\n",
      "the period of instruction in a school; the time period when school is in session\n",
      "Synset('school.n.06')\n",
      "an educational institution's faculty and students\n"
     ]
    }
   ],
   "source": [
    "def originalLesk(desc_list,word,pos):\n",
    "    \n",
    "    # based on the description and the word, tries to find most appropriate wordnet definition \n",
    "    # based on number of common words between the description and the definition\n",
    "    \n",
    "    def compare_glosses(list1,list2):\n",
    "        return len([word for word in set(list1) if word in set(list2)])\n",
    "\n",
    "    syn = wordnet.synsets(word)\n",
    "    scores = []\n",
    "    for i in syn:\n",
    "        if i.pos() == pos:\n",
    "            def_score = compare_glosses(nltk.word_tokenize(i.definition()),desc_list)\n",
    "            scores.append(def_score)\n",
    "            \n",
    "    for i in syn:\n",
    "        if i.pos() == pos:\n",
    "            def_score = compare_glosses(nltk.word_tokenize(i.definition()),desc_list)\n",
    "            if def_score == max(scores):\n",
    "                print(i)\n",
    "                print(i.definition())\n",
    "            \n",
    "        \n",
    "originalLesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school','n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7099598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('school.n.01') 878 an educational institution\n",
      "Synset('school.n.02') 899 a building where young people receive education\n",
      "Synset('school.n.03') 2541 the process of being formally educated at a school\n",
      "Synset('school.n.04') 1116 a body of creative artists or writers or thinkers linked by a similar style or by similar teachers\n",
      "Synset('school.n.05') 2210 the period of instruction in a school; the time period when school is in session\n",
      "Synset('school.n.06') 2156 an educational institution's faculty and students\n",
      "Synset('school.n.07') 755 a large group of fish\n",
      "final decision:\n",
      "Synset('school.n.03')\n",
      "the process of being formally educated at a school\n"
     ]
    }
   ],
   "source": [
    "def extendedLesk(desc_list,myword,pos):\n",
    "    \n",
    "    def compare_glosses(list1,list2):\n",
    "        return len([word for word in set(list1) if word in set(list2)])\n",
    "    \n",
    "    def matches(list1c, list2c):\n",
    "        list1=list1c.copy()\n",
    "        list2=list2c.copy()\n",
    "        while True:\n",
    "            mbs = difflib.SequenceMatcher(None, list1, list2).get_matching_blocks()\n",
    "            if len(mbs) == 1: break\n",
    "            for i, j, n in mbs[::-1]:\n",
    "                if n > 0: yield list1[i: i + n]\n",
    "                del list1[i: i + n]\n",
    "                del list2[j: j + n]\n",
    "    # lemmatize, get pos in wordnet format and remove non information words(linkers)\n",
    "    def process(tokenized_sent):\n",
    "        \n",
    "        # transform from treebank tagging to wordnet compatible\n",
    "        def get_wordnet_pos(treebank_tag):\n",
    "            if treebank_tag.startswith('J'):\n",
    "                return wordnet.ADJ\n",
    "            elif treebank_tag.startswith('V'):\n",
    "                return wordnet.VERB\n",
    "            elif treebank_tag.startswith('N'):\n",
    "                return wordnet.NOUN\n",
    "            elif treebank_tag.startswith('R'):\n",
    "                return wordnet.ADV\n",
    "            else:\n",
    "                return ''\n",
    "            \n",
    "        lemmatizer = WordNetLemmatizer() \n",
    "        # tuple (lemmatized word, pos tag)\n",
    "        return [(lemmatizer.lemmatize(pair[0].lower(), get_wordnet_pos(pair[1])),get_wordnet_pos(pair[1])) for pair in nltk.pos_tag(tokenized_sent) if get_wordnet_pos(pair[1])!='']\n",
    "    \n",
    "    \n",
    "    def get_synsets(word):\n",
    "        return wordnet.synsets(word[0],word[1])\n",
    "    \n",
    "    tagged_list = process(desc_list)\n",
    "    synsets = {} \n",
    "    for word in tagged_list: \n",
    "        related = {} \n",
    "        for syn in get_synsets(word): # for all synsets of each word get all things\n",
    "            related[syn] = {'hypernyms':syn.hypernyms(),\n",
    "                            'hyponyms':syn.hyponyms(),\n",
    "                            'part_meronyms':syn.part_meronyms(),\n",
    "                            'substance_meronyms':syn.substance_meronyms(),\n",
    "                            'member_meronyms':syn.member_meronyms(),\n",
    "                            'part_holonyms':syn.part_holonyms(),\n",
    "                            'substance_holonyms':syn.substance_holonyms(),\n",
    "                            'member_holonyms':syn.member_holonyms(),\n",
    "#                             'troponyms':syn.troponyms(),\n",
    "                            'attributes':syn.attributes(),\n",
    "                            'similar–to':syn.similar_tos(),\n",
    "                            'also–see':syn.also_sees()\n",
    "                           }\n",
    "        synsets[word]=related\n",
    "    \n",
    "    extended_glosses = [] # get their definitions\n",
    "    for word in tagged_list:\n",
    "        x = synsets[word]\n",
    "        for key,value in x.items():\n",
    "            for k,v in value.items():\n",
    "                for syn in v:\n",
    "                    extended_glosses.append(nltk.word_tokenize(syn.definition()))\n",
    "                    \n",
    "    maximum = -1\n",
    "    mysyn = None\n",
    "    # get the scores based on the longest common phrase\n",
    "    for syn in wordnet.synsets(myword):\n",
    "        if syn.pos() == pos: \n",
    "            x = 0\n",
    "            for defi in extended_glosses:\n",
    "                tokenized = nltk.word_tokenize(syn.definition())\n",
    "\n",
    "                match = list(matches(tokenized,defi))\n",
    "                if match != []:\n",
    "                    for i in match[0]:\n",
    "                        x+=len(i)*len(i)\n",
    "            if x >maximum:\n",
    "                maximum = x\n",
    "                mysyn=syn\n",
    "            print(syn,x,syn.definition())\n",
    "            \n",
    "    print('final decision:')\n",
    "    print(mysyn)\n",
    "    print(mysyn.definition())\n",
    "        \n",
    "            \n",
    "    \n",
    "extendedLesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school','n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df052d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673935d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
