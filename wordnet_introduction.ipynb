{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838fefc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sandu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('school.n.01'),\n",
       " Synset('school.n.02'),\n",
       " Synset('school.n.03'),\n",
       " Synset('school.n.04'),\n",
       " Synset('school.n.05'),\n",
       " Synset('school.n.06'),\n",
       " Synset('school.n.07'),\n",
       " Synset('school.v.01'),\n",
       " Synset('educate.v.03'),\n",
       " Synset('school.v.03')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "wordnet.synsets('school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1420493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feline mammal usually having thick soft fur and no ability to roar: domestic cats; wildcats\n",
      "an informal term for a youth or man\n",
      "a spiteful woman gossip\n",
      "the leaves of the shrub Catha edulis which are chewed like tobacco or used to make tea; has the effect of a euphoric stimulant\n",
      "a whip with nine knotted cords\n",
      "a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n",
      "any of several large cats typically able to roar and living in the wild\n",
      "a method of examining body organs by scanning them with X rays and using a computer to construct a series of cross-sectional scans along a single axis\n",
      "beat with a cat-o'-nine-tails\n",
      "eject the contents of the stomach through the mouth\n"
     ]
    }
   ],
   "source": [
    "def f1(word):\n",
    "    for syn in wordnet.synsets(word):\n",
    "        print(syn.definition())\n",
    "f1('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaac3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an institution dedicated to education\n",
      "a group of persons associated by some common tie or occupation and regarded as an entity\n"
     ]
    }
   ],
   "source": [
    "def f2(word1, word2):\n",
    "    syn1 = [i.hypernyms() for i in wordnet.synsets(word1)]\n",
    "    syn2 = [i.hypernyms() for i in wordnet.synsets(word2)]\n",
    "\n",
    "    syn3=[]\n",
    "    [syn3.append(i) for i in syn1 if i in syn2 if i not in syn3]\n",
    "    if syn3!= []:\n",
    "        for i in syn3:\n",
    "            print(i[0].definition())\n",
    "f2('school','university')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fcebcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[Synset('animalia.n.01')]\n",
      "[Synset('face.n.07'), Synset('head.n.01')]\n",
      "[Synset('animal_tissue.n.01')]\n",
      "[]\n",
      "\n",
      "([Synset('animalia.n.01')], [Synset('face.n.07'), Synset('head.n.01'), Synset('animal_tissue.n.01')])\n"
     ]
    }
   ],
   "source": [
    "def f3(syn):\n",
    "    holo1 = syn.part_holonyms()\n",
    "    holo2 = syn.substance_holonyms()\n",
    "    holo3 = syn.member_holonyms()\n",
    "    holo =holo1+holo2+holo3\n",
    "    \n",
    "    mero1 = syn.part_meronyms()\n",
    "    mero2 = syn.substance_meronyms()\n",
    "    mero3 = syn.member_meronyms()\n",
    "    mero = mero1+mero2+mero3\n",
    "    \n",
    "    return (holo,mero)\n",
    "\n",
    "syn1 = wordnet.synset('animal.n.01')\n",
    "print(syn1.part_holonyms())\n",
    "print(syn1.substance_holonyms())\n",
    "print(syn1.member_holonyms())\n",
    "print(syn1.part_meronyms())\n",
    "print(syn1.substance_meronyms())\n",
    "print(syn1.member_meronyms())\n",
    "print()\n",
    "print(f3(syn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988378bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cell.n.01')->Synset('compartment.n.01')->Synset('space.n.02')->Synset('amorphous_shape.n.01')->Synset('shape.n.02')->Synset('attribute.n.02')->Synset('abstraction.n.06')->Synset('entity.n.01')->[]\n",
      "Synset('cell.n.01')->Synset('compartment.n.01')->Synset('space.n.02')->Synset('location.n.01')->Synset('object.n.01')->Synset('physical_entity.n.01')->Synset('entity.n.01')->[]\n"
     ]
    }
   ],
   "source": [
    "def f4(syn):\n",
    "    def print_path(path):\n",
    "        for i in path:\n",
    "            print(i,end='->')\n",
    "        print('[]')\n",
    "    def rec(syn):\n",
    "        paths.append(syn)\n",
    "        if len(syn.hypernyms())==0:\n",
    "            print_path(paths)\n",
    "        for hyp in syn.hypernyms():   \n",
    "            rec(hyp)\n",
    "        paths.remove(syn)\n",
    "        \n",
    "    paths = []\n",
    "    rec(syn)\n",
    "    \n",
    "syn2 = wordnet.synset('cell.n.01')\n",
    "f4(syn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14491190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('carnivore.n.01')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f5(syn1,syn2):\n",
    "    #get all possible hypernym paths to root for synset\n",
    "    def f4mod(syn):\n",
    "        path_list = []\n",
    "        \n",
    "        def rec(syn):\n",
    "            paths.append(syn)\n",
    "            if len(syn.hypernyms())==0:\n",
    "                path_list.append(paths.copy())\n",
    "            for hyp in syn.hypernyms():   \n",
    "                rec(hyp)\n",
    "            paths.remove(syn)\n",
    "        paths = []\n",
    "        rec(syn)\n",
    "        return path_list\n",
    "\n",
    "    def distance(hyp,path1,path2):\n",
    "        return path1.index(hyp)+path2.index(hyp)\n",
    "    \n",
    "\n",
    "    pl1 = f4mod(syn1)\n",
    "    pl2 = f4mod(syn2)\n",
    "        \n",
    "#     print(pl1)\n",
    "#     print()\n",
    "#     print(pl2)\n",
    "#     print()\n",
    "\n",
    "    # get common hypernyms of both synsets\n",
    "    common_hyp=[]\n",
    "    for path1 in pl1:\n",
    "        for path2 in pl2:\n",
    "            for i in path1:\n",
    "                if i in path2:\n",
    "                    common_hyp.append(i)\n",
    "                    \n",
    "    common_hyp=list(dict.fromkeys(common_hyp))\n",
    "    \n",
    "    # get the distance d1(k)+d2(k) for each hypernym in its respective path\n",
    "    distances =[]\n",
    "    for hyp in common_hyp:\n",
    "        for path1 in pl1:\n",
    "            for path2 in pl2:\n",
    "                if hyp in path1:\n",
    "                    if hyp in path2:\n",
    "                        distances.append((hyp,distance(hyp,path1,path2)))\n",
    "\n",
    "    # take the smallest distace\n",
    "    distances.sort(key=lambda x:x[1])\n",
    "    minimum = distances[0][1]\n",
    "    \n",
    "    # save all hypernyms that minimize the distance between the two synsets\n",
    "    hyp_list = []\n",
    "    for i in distances:\n",
    "        if i[1]==minimum:\n",
    "            hyp_list.append(i[0])\n",
    "    \n",
    "    return hyp_list\n",
    "    \n",
    "syn3 = wordnet.synset('cat.n.01')\n",
    "syn4 = wordnet.synset('dog.n.01')\n",
    "f5(syn3,syn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "77543283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feline', 'dog', 'mouse', 'animal', 'pet', 'object', 'alien', 'tree', 'house', 'public_school']\n",
      "['feline', 'dog', 'mouse', 'animal', 'pet', 'alien', 'tree', 'house', 'object', 'public_school']\n",
      "['feline', 'dog', 'mouse', 'animal', 'pet', 'object', 'alien', 'tree', 'house', 'public_school']\n"
     ]
    }
   ],
   "source": [
    "def f6(syn,synlist):\n",
    "    # one idea for this is to use the same metric we used previously,\n",
    "    # namely to check the closest hypernym that pertains to both synsets\n",
    "    #get all possible hypernym paths to root for synset\n",
    "    def f5mod(syn1,syn2):\n",
    "        def f4mod(syn):\n",
    "            path_list = []\n",
    "\n",
    "            def rec(syn):\n",
    "                paths.append(syn)\n",
    "                if len(syn.hypernyms())==0:\n",
    "                    path_list.append(paths.copy())\n",
    "                for hyp in syn.hypernyms():   \n",
    "                    rec(hyp)\n",
    "                paths.remove(syn)\n",
    "            paths = []\n",
    "            rec(syn)\n",
    "            return path_list\n",
    "\n",
    "        def distance(hyp,path1,path2):\n",
    "            return path1.index(hyp)+path2.index(hyp)\n",
    "\n",
    "\n",
    "        pl1 = f4mod(syn1)\n",
    "        pl2 = f4mod(syn2)\n",
    "\n",
    "        # get common hypernyms of both synsets\n",
    "        common_hyp=[]\n",
    "        for path1 in pl1:\n",
    "            for path2 in pl2:\n",
    "                for i in path1:\n",
    "                    if i in path2:\n",
    "                        common_hyp.append(i)\n",
    "\n",
    "        common_hyp=list(dict.fromkeys(common_hyp))\n",
    "\n",
    "        # get the distance d1(k)+d2(k) for each hypernym in its respective path\n",
    "        distances =[]\n",
    "        for hyp in common_hyp:\n",
    "            for path1 in pl1:\n",
    "                for path2 in pl2:\n",
    "                    if hyp in path1:\n",
    "                        if hyp in path2:\n",
    "                            distances.append((hyp,distance(hyp,path1,path2)))\n",
    "\n",
    "        # take the smallest distace\n",
    "        distances.sort(key=lambda x:x[1])\n",
    "        minimum = distances[0][1]\n",
    "\n",
    "        # save all hypernyms that minimize the distance between the two synsets\n",
    "        hyp_list = []\n",
    "        for i in distances:\n",
    "            if i[1]==minimum:\n",
    "                hyp_list.append(i)\n",
    "                \n",
    "        return hyp_list[0][1]\n",
    "    \n",
    "    words = []\n",
    "    for i in synlist:\n",
    "        words.append((i, f5mod(syn,wordnet.synsets(i)[0])))\n",
    "        \n",
    "    words.sort(key=lambda x:x[1])\n",
    "    word_list = []\n",
    "    for i in words:\n",
    "        word_list.append(i[0])\n",
    "    \n",
    "    print(word_list)\n",
    "\n",
    "def f6v2(syn,synlist):\n",
    "    # now we use wup similarity from wordnet\n",
    "    \n",
    "    words = []\n",
    "    for i in synlist:\n",
    "        words.append((i,syn.wup_similarity(wordnet.synsets(i)[0])))\n",
    "        \n",
    "    words.sort(key=lambda x:x[1],reverse=True)\n",
    "    word_list = []\n",
    "    for i in words:\n",
    "        word_list.append(i[0])\n",
    "    \n",
    "    print(word_list)    \n",
    "    \n",
    "def f6v3(syn,synlist):\n",
    "    # now we use path similarity from wordnet\n",
    "    # by the results, it looks like this is what I implemented on f5\n",
    "    words = []\n",
    "    for i in synlist:\n",
    "        words.append((i,syn.path_similarity(wordnet.synsets(i)[0])))\n",
    "        \n",
    "    words.sort(key=lambda x:x[1],reverse=True)\n",
    "    word_list = []\n",
    "    for i in words:\n",
    "        word_list.append(i[0])\n",
    "    \n",
    "    print(word_list)    \n",
    "    \n",
    "syn5 = wordnet.synset('cat.n.01')\n",
    "f6(syn5,['animal','tree','house','object','public_school','mouse','dog','feline','alien','pet'])\n",
    "f6v2(syn5,['animal','tree','house','object','public_school','mouse','dog','feline','alien','pet'])\n",
    "f6v3(syn5,['animal','tree','house','object','public_school','mouse','dog','feline','alien','pet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35640ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f7(syn1, syn2): # syn1 and syn2 are part meronyms of synk iif synk is a common part holonym\n",
    "    def myholonyms(syn):\n",
    "        holo,_ = f3(syn)\n",
    "        return holo\n",
    "    \n",
    "    def allholonyms(synlist):\n",
    "        newlist = []\n",
    "        for i in synlist:\n",
    "            newlist =newlist + myholonyms(i) \n",
    "        return  list(dict.fromkeys(synlist+newlist))\n",
    "    \n",
    "    def rec(syn):\n",
    "        newsyn = allholonyms(syn)\n",
    "        if newsyn!=syn:\n",
    "            return rec(newsyn)\n",
    "        else:\n",
    "            return newsyn\n",
    "    \n",
    "    # holonym list\n",
    "#     print(rec([syn1]))\n",
    "#     print(rec([syn2]))\n",
    "    \n",
    "    if [syn for syn in rec([syn1]) if syn in rec([syn2])] !=[]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "syn6 = wordnet.synset('water.n.01')\n",
    "syn7 = wordnet.synset('ground.n.01')\n",
    "f7(syn6,syn7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8d7b6b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['goodness', 'near', 'safe', 'just', 'commodity', 'salutary', 'well', 'full', 'respectable', 'serious', 'honest', 'ripe', 'proficient', 'trade_good', 'practiced', 'in_force', 'secure', 'unspoiled', 'honorable', 'beneficial', 'thoroughly', 'skillful', 'skilful', 'estimable', 'sound', 'upright', 'right', 'soundly', 'adept', 'dependable', 'effective', 'undecomposed', 'unspoilt', 'good', 'dear', 'in_effect', 'expert'], ['evil', 'ill', 'badness', 'evilness', 'bad']]\n",
      "benefit\n",
      "moral excellence or admirableness\n",
      "that which is pleasing or valuable or useful\n",
      "articles of commerce\n",
      "having desirable or positive qualities especially those suitable for a thing specified\n",
      "having the normally expected amount\n",
      "morally admirable\n",
      "deserving of esteem and respect\n",
      "promoting or enhancing well-being\n",
      "agreeable or pleasing\n",
      "of moral excellence\n",
      "having or showing knowledge and skill and aptitude\n",
      "thorough\n",
      "with or in a close or intimate relationship\n",
      "financially sound\n",
      "most suitable or right for a particular purpose\n",
      "resulting favorably\n",
      "exerting force or influence\n",
      "capable of pleasing\n",
      "appealing to the mind\n",
      "in excellent physical condition\n",
      "tending to promote physical well-being; beneficial to health\n",
      "not forged\n",
      "not left to spoil\n",
      "generally admired\n",
      "(often used as a combining form) in a good or proper or satisfactory manner or to a high standard (`good' is a nonstandard dialectal variant for `well')\n",
      "completely and absolutely (`good' is sometimes used informally for `thoroughly')\n"
     ]
    }
   ],
   "source": [
    "def f8(adj):\n",
    "    synonyms = []\n",
    "    antonyms = []\n",
    "    counter = 0\n",
    "    for syn in wordnet.synsets(adj):\n",
    "        counter +=1\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "            if l.antonyms():\n",
    "                for i in l.antonyms():\n",
    "                    antonyms.append(i.name())\n",
    "    print( [list(set(synonyms)),list(set(antonyms))])\n",
    "    if counter >1:\n",
    "        for syn in wordnet.synsets(adj):\n",
    "            print(syn.definition())\n",
    "            \n",
    "\n",
    "f8('good')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
